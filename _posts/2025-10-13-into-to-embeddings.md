
---

###  Embeddings:

> “A model finds potential embeddings by projecting the high-dimensional space of initial data vectors into a lower-dimensional space.”

sounds complex, but it’s actually describing **dimensionality reduction** — a key idea in representation learning.

---

## 1️ High-dimensional data

Every raw data point — a word, an image, a user — can be represented as a **vector** of numbers.

* For example, if we have 10,000 unique words, we might represent each word as a **10,000-dimensional vector** (one-hot encoding → only one position is 1, the rest are 0).
* That’s a *very high-dimensional* space — huge, sparse, and inefficient.

---

## 2️ Projection into a lower-dimensional space

Instead of working with those enormous, mostly-empty vectors, models **learn to compress** them into **dense, smaller vectors** — say, 100–768 dimensions.

That process — going from 10,000 → 300 dimensions — is what we call **projection into a lower-dimensional space**.

It’s not a random projection; it’s **learned** so that meaningful relationships are preserved.

---

## 3️ What are “embeddings”?

An **embedding** is this new, compact vector representation.
It captures the **semantic meaning** of the input.

Example:

| Word    | Raw (one-hot)   | Learned Embedding (dense) |
| ------- | --------------- | ------------------------- |
| “king”  | [0,0,0,...,1,0] | [0.21, 0.88, -0.35, ...]  |
| “queen” | [0,0,0,...,0,1] | [0.19, 0.91, -0.40, ...]  |

Now the vectors for “king” and “queen” are close to each other in embedding space because they have similar meaning.

---

## 4️ Why do we do this?

Because in the lower-dimensional embedding space:

* **Similar meanings → nearby points**
* **Different meanings → far apart points**

So, the geometry of that space encodes relationships.
For example:

> king − man + woman ≈ queen

That’s possible because embeddings preserve relationships in meaning, not just surface forms.

---

## 5️ Mathematically

If the original data lives in **high-dimensional space** (say, ℝⁿ),
then the embedding function **f(x)** maps it into **ℝᵈ**,
where d ≪ n.

Formally:
[
f: \mathbb{R}^n \rightarrow \mathbb{R}^d
]
where **f** is a neural network layer (often learned during training).

---

## 6️ In the context of LLMs

In LLMs:

* Each token (word or subword) gets converted to an **embedding vector**.
* These embeddings are the input to the **Transformer layers**.
* The model learns to adjust these embeddings so that words used in similar contexts have similar vectors.

This is what allows LLMs to *understand meaning* and *reason about text* in a continuous, mathematical way.

---

###  In short:

> A model learns embeddings by **compressing** high-dimensional, raw input representations into a **dense, lower-dimensional space** where **semantic relationships** are preserved.

It’s like going from:

* A massive, awkward dictionary of words
  → to
* A compact “map” where meaning is encoded as position and distance.


